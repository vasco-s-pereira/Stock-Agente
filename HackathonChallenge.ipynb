{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkabTiKo13dQ"
      },
      "source": [
        "# **Challenge Overview – Stock Agent**\n",
        "\n",
        "Acting as consultants for an investment fund managing a portfolio of 11 stocks, your goal is to build an AI-powered solution that enhances investment decision-making. You may focus on the full portfolio or a specific subset. The aim is to demonstrate how AI can drive financial insights, whether through a trading agent, an analytical dashboard, or another innovative tool.\n",
        "<br>\n",
        "<br>\n",
        "### **Tech & Tools**\n",
        "\n",
        "It is mandatory to develop the solution in **Google Colab** using **Python**.\n",
        "\n",
        "Other than that, you are completely free to choose your own:\n",
        "\n",
        "•\tLibraries and packages: Use any tool you need (e.g., Pandas, Scikit-learn, LangChain, etc.)\n",
        "\n",
        "•\tVisualization tools: Python-based tools (Matplotlib, Seaborn), Power BI, Tableau, etc. (if you use external visualization tools, don't forget to include prints in the submission zip folder)\n",
        "\n",
        "•\tAI assistants: Feel free to consult ChatGPT, GitHub Copilot, Gemini, or any other.\n",
        "<br>\n",
        "<br>\n",
        "### **Tech Configuration**\n",
        "\n",
        "**1** - The second code cell contains the code needed to export the dataset for the 11 assets. All data is saved as individual .csv files in a data/ directory, named according to the asset and frequency (e.g., AMZN_hourly.csv or AMZN_daily.csv).\n",
        "\n",
        "**2** - The remaining cells include functions suggested by the dev team to help accelerate your solution. Each function comes with a description of its purpose and examples of expected usage. Feel free to use, adapt, extend, or completely rework them to fit your approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1zPh_63Zf3s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pandas==2.2.2 (from versions: 0.1, 0.2, 0.3.0, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.5.0, 0.6.0, 0.6.1, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.8.0, 0.8.1, 0.9.0, 0.9.1, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.19.2, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.21.0, 0.21.1, 0.22.0, 0.23.0, 0.23.1, 0.23.2, 0.23.3, 0.23.4, 0.24.0, 0.24.1, 0.24.2, 0.25.0, 0.25.1, 0.25.2, 0.25.3, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.2.5, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.3.4, 1.3.5, 1.4.0rc0, 1.4.0, 1.4.1, 1.4.2, 1.4.3, 1.4.4, 1.5.0rc0, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 2.0.0rc0, 2.0.0rc1, 2.0.0, 2.0.1, 2.0.2, 2.0.3)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pandas==2.2.2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install yfinance==0.2.59 pandas==2.0.3 matplotlib==3.7.5 seaborn==0.13.2 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izLkVAECdHm2"
      },
      "source": [
        "**Data Fetching**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXwnzNolZiTb"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "\n",
        "# List of symbols to download\n",
        "symbols = [\"AMZN\", \"AAPL\", \"GOOGL\", \"MSFT\", \"UDMY\", \"NXE\", \"SPY\",\n",
        "           \"CDR.WA\", \"EH\", \"BTC-USD\", \"ETH-USD\"]\n",
        "\n",
        "# Set date range\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=729)\n",
        "\n",
        "start_str = start_date.strftime('%Y-%m-%d')\n",
        "end_str = end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "print(f\"Downloading hourly data from {start_str} to {end_str} (729 days)\")\n",
        "\n",
        "# Create data directory if it doesn't exist\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Download data for each symbol\n",
        "for symbol in symbols:\n",
        "    print(f\"\\nDownloading hourly data for {symbol}...\")\n",
        "\n",
        "    try:\n",
        "        # Download hourly data\n",
        "        data = yf.download(symbol, start=start_str, end=end_str, interval=\"1h\", progress=False)\n",
        "\n",
        "        if not data.empty:\n",
        "            # Reset index to make Datetime a column\n",
        "            data.reset_index(inplace=True)\n",
        "\n",
        "            # Save to CSV\n",
        "            safe_name = symbol.replace('-', '_').replace('.', '_')\n",
        "            filename = f\"data/{safe_name}_hourly.csv\"\n",
        "            data.to_csv(filename, index=False)\n",
        "            print(f\"Successfully downloaded {len(data)} rows of hourly data for {symbol}\")\n",
        "\n",
        "            # Display the first 5 rows of data\n",
        "            print(f\"\\nFirst 5 rows of {symbol} data:\")\n",
        "            print(data.head())\n",
        "\n",
        "        else:\n",
        "            print(f\"No hourly data available for {symbol}\")\n",
        "\n",
        "            # Try daily data instead\n",
        "            print(f\"Attempting to download daily data for {symbol} instead...\")\n",
        "            daily_data = yf.download(symbol, start=(start_date - timedelta(days=365)).strftime('%Y-%m-%d'),\n",
        "                                    end=end_str, interval=\"1d\", progress=False)\n",
        "\n",
        "            if not daily_data.empty:\n",
        "                daily_data.reset_index(inplace=True)\n",
        "                filename = f\"data/{symbol.replace('-', '_').replace('.', '_')}_daily.csv\"\n",
        "                daily_data.to_csv(filename, index=False)\n",
        "                print(f\"Successfully downloaded {len(daily_data)} rows of daily data for {symbol}\")\n",
        "\n",
        "                # Display the first 5 rows of daily data\n",
        "                print(f\"\\nFirst 5 rows of {symbol} daily data:\")\n",
        "                print(daily_data.head())\n",
        "            else:\n",
        "                print(f\"Failed to download any data for {symbol}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading data for {symbol}: {str(e)}\")\n",
        "\n",
        "# Create summary of downloaded files\n",
        "file_info = []\n",
        "for symbol in symbols:\n",
        "    safe_name = symbol.replace('-', '_').replace('.', '_')\n",
        "    hourly_path = f\"data/{safe_name}_hourly.csv\"\n",
        "    daily_path = f\"data/{safe_name}_daily.csv\"\n",
        "\n",
        "    if os.path.exists(hourly_path):\n",
        "        df = pd.read_csv(hourly_path)\n",
        "        file_info.append({\n",
        "            'Symbol': symbol,\n",
        "            'Filename': hourly_path,\n",
        "            'Rows': len(df),\n",
        "            'Start Date': df['Datetime'].iloc[0],\n",
        "            'End Date': df['Datetime'].iloc[-1],\n",
        "            'Frequency': 'Hourly'\n",
        "        })\n",
        "    elif os.path.exists(daily_path):\n",
        "        df = pd.read_csv(daily_path)\n",
        "        file_info.append({\n",
        "            'Symbol': symbol,\n",
        "            'Filename': daily_path,\n",
        "            'Rows': len(df),\n",
        "            'Start Date': df['Date'].iloc[0],\n",
        "            'End Date': df['Date'].iloc[-1],\n",
        "            'Frequency': 'Daily'\n",
        "        })\n",
        "    else:\n",
        "        file_info.append({\n",
        "            'Symbol': symbol,\n",
        "            'Filename': 'N/A',\n",
        "            'Rows': 0,\n",
        "            'Start Date': 'N/A',\n",
        "            'End Date': 'N/A',\n",
        "            'Frequency': 'N/A'\n",
        "        })\n",
        "\n",
        "# Display file summary\n",
        "file_summary = pd.DataFrame(file_info)\n",
        "print(\"\\nFile Summary:\")\n",
        "print(file_summary)\n",
        "\n",
        "print(\"\\nData collection complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_w7yZnhc1X-"
      },
      "source": [
        "**Possible Implementation Ideas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yp-PJmrXa0ak"
      },
      "outputs": [],
      "source": [
        "# Perform basic data exploration\n",
        "def explore_data(data):\n",
        "    \"\"\"Generate basic statistics and visualizations of the market data.\"\"\"\n",
        "    # Example steps:\n",
        "    # - Print summary statistics\n",
        "    # - Plot closing prices over time\n",
        "    # - Identify any outliers or anomalies\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5PVeJvGa5fK"
      },
      "outputs": [],
      "source": [
        "# Visualize technical indicators\n",
        "def visualize_indicators(data):\n",
        "    \"\"\"Add and plot technical indicators like SMA, EMA, RSI, etc.\"\"\"\n",
        "    # Example steps:\n",
        "    # - Compute simple and exponential moving averages\n",
        "    # - Plot with the original closing price\n",
        "    # - Highlight crossover points\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElIlQHg4by8U"
      },
      "outputs": [],
      "source": [
        "# Perform ML Analysis to identify trends and make predictions\n",
        "def analyze_market_trends(market_data):\n",
        "    \"\"\"Apply ML techniques to analyze stock/crypto trends.\"\"\"\n",
        "    # Example steps:\n",
        "    # - Normalize data for better trend detection\n",
        "    # - Apply time series models (ARIMA, LSTMs, etc.)\n",
        "    # - Identify market linearity and anomalies\n",
        "    # - Predict future price movements\n",
        "\n",
        "    return {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG1UmuHlb1YJ"
      },
      "outputs": [],
      "source": [
        "# Generate trading signals based on strategy\n",
        "def generate_trading_signals(data):\n",
        "    \"\"\"Define and apply rules to generate buy/sell signals.\"\"\"\n",
        "    # Example strategy ideas:\n",
        "    # - SMA crossover\n",
        "    # - RSI-based entry/exit\n",
        "    # - Price breakout detection\n",
        "\n",
        "    return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyBNQBr6b3GB"
      },
      "outputs": [],
      "source": [
        "# Simulate portfolio performance\n",
        "def simulate_portfolio(data, signals):\n",
        "    \"\"\"Backtest the strategy using historical data and generated signals.\"\"\"\n",
        "    # Example steps:\n",
        "    # - Initialize a virtual portfolio\n",
        "    # - Buy/sell based on signals\n",
        "    # - Track cumulative returns and drawdowns\n",
        "\n",
        "    return {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQjK6D-ab5Wm"
      },
      "outputs": [],
      "source": [
        "# Evaluate strategy performance\n",
        "def evaluate_strategy(results):\n",
        "    \"\"\"Evaluate strategy using key metrics.\"\"\"\n",
        "    # Example metrics:\n",
        "    # - Cumulative returns\n",
        "    # - Sharpe ratio\n",
        "    # - Maximum drawdown\n",
        "\n",
        "    return {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-loHOJTRb7yL"
      },
      "outputs": [],
      "source": [
        "# Wrap-up and discussion\n",
        "def reflect_on_findings():\n",
        "    \"\"\"Summarize insights and propose next steps.\"\"\"\n",
        "    # Example:\n",
        "    # - What worked? What didn’t?\n",
        "    # - How would you improve the strategy?\n",
        "    # - What other data might help?\n",
        "\n",
        "    return None\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
